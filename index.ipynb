{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About\n\nThe purpose of this document is to do the following:\n- describe a set of data pulled from a Dataverse\n- provide Python code and a simple computing environment for working with the data (without the need to manually build your own)\n- perform a set of checks and validation on the data\n\n**NOTE: the code and this environment may become deprecated at some point in time and may no longer function as originally designed. For context, this notebook was last run on:**","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\ncurrentDateAndTime = datetime.now()\nprint(currentDateAndTime)","metadata":{"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"2023-04-24 20:56:01.466720\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using this Jupyter notebook on data from the Dataverse\n\nThis Jupyter notebook uses a Python environment, along with the Python `pandas` module, to retrieve STATA data from a Dataverse and copy it to a dataframe. Our Python environment is defined in the `environment.yml` configuration file, so if we needed some additional Python modules to build charts or graphs later, this is where we would add those modules. We chose STATA as the data source because the pandas module will automatically assign columns/variables as categorical if variable value labels are assigned in STATA. If we only downloaded the default .tab file from the Dataverse you would only have the raw data, which would require manually mapping the variable categories to the data.\n\nNote: If you are more familiar with using the R project to work data than Python, then you could modify this notebook to use the 'foreign' package for R [https://cran.r-project.org/web/packages/foreign/foreign.pdf], but we are not including every possible use-case in this document and are only using Python.","metadata":{}},{"cell_type":"markdown","source":"## Retrieve data from the Dataverse\n\nNow we can move on to the fun stuff. Below we will begin with some code we will need to work with our data. We need to specific the files we want to analyze from the Dataverse and import the Python module (pandas) that will help us describe and make sense of the data. No output will be printed from this code as we are simply retrieving the data.","metadata":{"tags":[]}},{"cell_type":"code","source":"# pull the original STATA file at a specific version (using ?format=original&version=5.2) from the Dataverse, otherwise we would simply be pulling the CSV file without the categories included\nDATA_FILE1 = 'https://demo.dataverse.org/api/access/datafile/2062199?format=original&version=5.2'  # this first file contains some demographics; we want to be explicit on the data version and file format so everyone knows exactly which files are being used\n# see https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html on how to group and describe data\nimport pandas as pd  # tell Python we want to use the pandas module\ndf1 = pd.read_stata(DATA_FILE1)  # read the data file from the URL defined in the `DATA_FILE1` variable and save it to a dataframe named `df1`","metadata":{"tags":[],"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Print general stats from the data\n\nNow we will print some general statistics on the data we just downloaded and saved to dataframes.","metadata":{}},{"cell_type":"code","source":"print(\"Start dataset 1 statistics\\n=======================================\")\nprint(df1.head(3))  # print the first three rows of the dataframe, including the header (which might be wrapped to a second line)\n# print(df1['E03RADRPAKKL'].dtype) # this should show the data type as categorical\n# print(df1[['E03RADRPAKKL','E03RADRPAKKL','E03AGE','E03GENDER']].describe())  # prints general stats for select variables\nprint(df1.describe())  # prints general stats for all vars (this is useful because it can easily point out data errors, such as duplicates in a unique field where the `count` may be reported as 628 but the `unique` may be showing 627)\nprint(\"=======================================\\nend dataset 1 statistics\")","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Start dataset 1 statistics\n=======================================\n                           E03SUBJECTID E03RADLPAKKL  E03RADRPAKKL E03AGE   \n0  e731b53a-c413-41bd-8018-14f3fb7cfb7b     Moderate      Moderate  50-54  \\\n1  86988f07-1c1d-42fc-b23b-6ef7b829a7e1          NaN          Mild  60-64   \n2  3b58c0d3-a33b-4a0c-b231-34985f7d23eb         Mild  Questionable  65-70   \n\n  E03GENDER  E03PASKL  E03PASKR  \n0    Female      None  Moderate  \n1    Female      None    Severe  \n2    Female  Moderate  Moderate  \n                                E03SUBJECTID E03RADLPAKKL  E03RADRPAKKL   \ncount                                    628          618           616  \\\nunique                                   627            6             6   \ntop     84882a65-ba24-42b2-bb29-0bd3ac001927        No OA  Questionable   \nfreq                                       2          237           216   \n\n       E03AGE E03GENDER E03PASKL E03PASKR  \ncount     628       628      627      627  \nunique      7         2        4        4  \ntop     65-70    Female     None     None  \nfreq      126       416      334      296  \n=======================================\nend dataset 1 statistics\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data curation and performing automated data validation and checks\n\nIt can be difficult to spot data issues unless you know what to look for. As a data curator, it is important to define the values you expect, or do not expect to see in a data column. For example, our `E03SUBJECTID` values should all be unique in our `df1` dataset, meaning the total number of values should equal the total number of unique values.\n\nIn the stats above, if were had read the data carfully we might have spotted that our `E03SUBJECTID` statistics do not look correct with regard to the unique value count in the column. With that in mind we should create reproducible checks on our data to ensure the data meets criteria we define for our data. This is especially useful if you will be uploading new versions of the data to the Dataverse frequently since you do not want to manually check for the same issues on new data. Plus, having the validation defined in a file gives the end-user confidence that you are not simply manually checking your data (or not checking your data), and instead can verify the data meets specific conditions automatically themselves.\n\nSince we expect our `E03SUBJECTID` column to contain unique values, we create a simple check using the Python code below:","metadata":{}},{"cell_type":"code","source":"# let us print our counts just so we have a visual on what the data looks like\nprint(\"total number of values for E03SUBJECTID: \",df1[\"E03SUBJECTID\"].count())\nprint(\"total number of distinct values for E03SUBJECTID: \",df1[\"E03SUBJECTID\"].unique().size)\n\n# we post an error if the E03SUBJECTID column does not contain distinct values\nif df1[\"E03SUBJECTID\"].count()!=df1[\"E03SUBJECTID\"].unique().size:\n    raise RuntimeError(\"***ERROR: The E03SUBJECTID column contains a duplicate value***\")\n    \n#df1.groupby([\"E03GENDER\"])[\"E03RADLPAKKL\"].count()\n\n# show some combined data (https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html)","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"total number of values for E03SUBJECTID:  628\ntotal number of distinct values for E03SUBJECTID:  627\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# we post an error if the E03SUBJECTID column does not contain distinct values\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE03SUBJECTID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m!=\u001b[39mdf1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE03SUBJECTID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***ERROR: The E03SUBJECTID column contains a duplicate value***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#df1.groupby([\"E03GENDER\"])[\"E03RADLPAKKL\"].count()\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# show some combined data (https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html)\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: ***ERROR: The E03SUBJECTID column contains a duplicate value***"],"ename":"RuntimeError","evalue":"***ERROR: The E03SUBJECTID column contains a duplicate value***","output_type":"error"}]},{"cell_type":"markdown","source":"As designed, the code throws an error saying that our `E03SUBJECTID` column contains a duplicate value. Now that we know our data does not pass inspection we can go back and correct the data and then rerun this notebook to verify the data passes inspection.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
